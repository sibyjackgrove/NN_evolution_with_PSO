{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siby\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.models import Model,Sequential\n",
    "from tensorflow.python.keras import Input\n",
    "from tensorflow.python.keras.layers import Dense,Add,add,BatchNormalization,Conv1D,concatenate,Flatten \n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications import MobileNet\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python import keras\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/earthquake_data\\\\earthquake.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = './data/power_data'\n",
    "folder_name = './data/earthquake_data'\n",
    "file_names = glob.glob(os.path.join(folder_name,'*.csv'))  #List only csv files\n",
    "file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_input_data_for_dataset(file_name): #rows = 100\n",
    "\n",
    "    #df_input=pd.read_csv(file_name.decode(),usecols=['Wind_MWh'])#, nrows=rows\n",
    "    df_input=pd.read_csv(file_name.decode(),usecols=['Latitude','Longitude','Depth'])#, nrows=rows\n",
    "        \n",
    "   \n",
    "    X_data = df_input.as_matrix()\n",
    "   \n",
    "    return X_data.astype('float32', copy=False)\n",
    "\n",
    "def _get_target_data_for_dataset(file_name): #rows = 100\n",
    "\n",
    "    #df_input=pd.read_csv(file_name.decode(),usecols=['Actual_Load_MWh'])#, nrows=rows\n",
    "    df_input=pd.read_csv(file_name.decode(),usecols=['Magnitude'])#, nrows=rows\n",
    "        \n",
    "   \n",
    "    X_data = df_input.as_matrix()\n",
    "   \n",
    "    return X_data.astype('float32', copy=False)\n",
    "\n",
    "def _get_validation_data_for_dataset(file_name): \n",
    "    valid_batch_size = 1000\n",
    "    #df_input=pd.read_csv(file_name.decode(),usecols=['Actual_Load_MWh'])#, nrows=rows\n",
    "    df_input=pd.read_csv(file_name,usecols=['Latitude','Longitude','Depth'],skiprows=range(1, 20000) )#\n",
    "    df_target=pd.read_csv(file_name,usecols=['Magnitude'],skiprows=range(1, 20000) )    \n",
    "   \n",
    "    X_data = df_input.as_matrix()\n",
    "    Y_data = df_target.as_matrix()\n",
    "   \n",
    "    return (X_data.astype('float32', copy=False),Y_data.astype('float32', copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "X_dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "X_dataset = X_dataset.flat_map(lambda file_name: tf.data.Dataset.from_tensor_slices(\n",
    "                                tf.reshape(tf.py_func(_get_input_data_for_dataset,[file_name], tf.float32),[-1,3])))\n",
    "\n",
    "X_dataset = X_dataset.batch(train_batch_size).repeat()\n",
    "X_iter = X_dataset.make_one_shot_iterator()\n",
    "X_batch = X_iter.get_next()\n",
    "\n",
    "Y_dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "Y_dataset = Y_dataset.flat_map(lambda file_name: tf.data.Dataset.from_tensor_slices(\n",
    "                                tf.reshape(tf.py_func(_get_target_data_for_dataset,[file_name], tf.float32),[-1,1])))\n",
    "Y_dataset = Y_dataset.batch(train_batch_size).repeat()\n",
    "Y_iter = Y_dataset.make_one_shot_iterator()\n",
    "Y_batch = Y_iter.get_next()\n",
    "\n",
    "XY_dataset = tf.data.Dataset.from_tensor_slices(_get_validation_data_for_dataset(file_names[0]))\n",
    "#XY_dataset = XY_dataset.flat_map(lambda file_name: tf.data.Dataset.from_tensor_slices(\n",
    "#                                tuple(tf.py_func(_get_validation_data_for_dataset,[file_name], [tf.float32,tf.float32]))))  \n",
    "XY_dataset = XY_dataset.batch(train_batch_size).repeat()\n",
    "XY_iter = XY_dataset.make_one_shot_iterator()\n",
    "XY_batch = XY_iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_model():\n",
    "    \"\"\" Class for neural network model.\"\"\"\n",
    "    \n",
    "    __counter = 0\n",
    "    max_layers = 5\n",
    "    max_neurons = 15\n",
    "    \n",
    "    def __init__(self,layers = 1, neurons = 3): \n",
    "        type(self).__counter += 1\n",
    "        self.layers = layers\n",
    "        self.neurons = neurons\n",
    "        self.model_ID = 'model_'+str(self.__counter)\n",
    "        self.make_FFNN(X_batch,Y_batch)\n",
    "    def __del__(self):\n",
    "        type(self).__counter -= 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def NN_instances():\n",
    "        return NN_model.__counter\n",
    "    \n",
    "    def make_FFNN(self,X_batch,Y_batch):\n",
    "        X_features = X_batch.get_shape()[1].value\n",
    "        Y_features = Y_batch.get_shape()[1].value\n",
    "        input_X1 = Input(tensor= X_batch,name='input_X1')\n",
    "        norm_X1 = tf.keras.layers.BatchNormalization(name='Batch_norm')(input_X1)\n",
    "        \n",
    "        for i in range(self.layers):\n",
    "            if i == 0:\n",
    "                y1 = Dense(units= self.neurons, activation='relu',name='layer_FC'+str(i+1))(norm_X1)\n",
    "            elif i>=1:\n",
    "                y1 = Dense(units= self.neurons, activation='relu',name='layer_FC'+str(i+1))(y1)\n",
    "        \n",
    "        y1 = Dense(units=Y_features,name='output_layer')(y1)\n",
    "        self.model = Model(inputs=input_X1,outputs=y1,name=self.model_ID)\n",
    "        self.model.compile('adam', 'mse', target_tensors=[Y_batch])\n",
    "        self.fitness = self.get_losses()\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def plot_model(self):\n",
    "       \n",
    "        plot_model(self.model, show_shapes = True,to_file=self.model_ID+'.svg')\n",
    "        SVG('./'+self.model_ID+'.svg')\n",
    "    \n",
    "    def show_model(self):\n",
    "        \"\"\"Show NN model details.\"\"\"\n",
    "\n",
    "        print(\"Model ID:{}, Fitness:{:3f}, Layers:{}, Neurons:{}\".format(self.model_ID,self.fitness,self.layers,self.neurons))\n",
    "    \n",
    "    def get_losses(self):\n",
    "        \"\"\"Train NN model details and get loss.\"\"\"\n",
    "        print(\"Training a new NN model with ID:{} having {} layers and {} neurons per layer.\".format(self.model.name,self.layers,self.neurons))\n",
    "        #return self.model.evaluate(steps=10)\n",
    "        return self.model.fit(steps_per_epoch=50, epochs=5,verbose=0).history['loss'][-1] #, validation_split=0.2,validation_data =XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO_NN_Particle(NN_model):\n",
    "    \"\"\"Class to encapsulate particle in swarm.\"\"\"\n",
    "    \n",
    "    __counter = 0\n",
    "    c1 = 0.1  #PSO inertial hyperparametre\n",
    "    \n",
    "    def __init__(self): \n",
    "        type(self).__counter += 1\n",
    "        layers =  random.randint(1, NN_model.max_layers)\n",
    "        neurons =  random.randint(1, NN_model.max_neurons) \n",
    "        super().__init__(layers,neurons) \n",
    "        \n",
    "        #self.make_FFNN(X_batch,Y_batch)\n",
    "        self.particle_ID = 'particle_'+str(self.__counter)\n",
    "        \n",
    "        self.best_fitness = self.fitness\n",
    "        self.best_layers = layers\n",
    "        self.best_neurons = neurons\n",
    "        \n",
    "        self.velocity_layers = 0\n",
    "        self.velocity_neurons = 0\n",
    "    \n",
    "    def __del__(self):\n",
    "        type(self).__counter -= 1\n",
    "    \n",
    "    def show_particle(self):\n",
    "        \"\"\"Show contents of swarm.\"\"\"\n",
    "        \n",
    "        print(\"Particle ID:{}, Best fitness:{:3f}, Best layers:{}, Best neurons:{}\".\\\n",
    "            format(self.particle_ID,self.best_fitness,self.best_layers,self.best_neurons))\n",
    "        super().show_model() \n",
    "    \n",
    "    def velocity_change_inertial(self):\n",
    "        \"\"\"Inertial component of particle velocity.\"\"\"\n",
    "        \n",
    "        self.velocity_change_inertial_layers =  (self.best_layers - self.layers)*self.c1*random.random()\n",
    "        self.velocity_change_inertial_neurons = (self.best_neurons - self.neurons)*self.c1*random.random()\n",
    "     \n",
    "    def update_particle_velocity(self):\n",
    "        \"\"\"Function to update particle velocity.\"\"\"       \n",
    "           \n",
    "        self.velocity_layers = self.velocity_layers +   self.velocity_change_inertial_layers +\\\n",
    "                                                        self.velocity_change_global_layers\n",
    "        self.velocity_neurons = self.velocity_neurons + self.velocity_change_inertial_neurons +\\\n",
    "                                                        self.velocity_change_global_neurons\n",
    "    \n",
    "    def update_particle_best(self):\n",
    "        \"\"\"Update particle best fitness.\"\"\"\n",
    "       \n",
    "        if self.fitness < self.best_fitness:\n",
    "            self.best_fitness = self.fitness\n",
    "            self.best_layers = self.layers\n",
    "            self.best_neurons = self.neurons\n",
    "    \n",
    "    def update_particle(self):\n",
    "        \"\"\"Update particle with new NN model and fitness.\"\"\"\n",
    "        \n",
    "        #self.layers =  min(self.max_layers,int(self.layers +   self.velocity_layers))\n",
    "        #self.neurons = min(self.max_neurons,int(self.neurons +   self.velocity_neurons))\n",
    "        #self.make_FFNN(X_batch,Y_batch)\n",
    "        layers =  min(self.max_layers,int(self.layers +   self.velocity_layers))\n",
    "        neurons = min(self.max_neurons,int(self.neurons +   self.velocity_neurons))\n",
    "        \n",
    "        if layers != self.layers or neurons != self.neurons:\n",
    "            print(\"Updating model for particle {}.\".format(self.particle_ID))    \n",
    "            super().__init__(layers,neurons)       \n",
    "            self.update_particle_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO_NN_Swarm(PSO_NN_Particle):\n",
    "    \"\"\"Class to encapsulate PSO algorithm.\"\"\"\n",
    "    \n",
    "    __counter = 0\n",
    "   \n",
    "    c2 =0.1  #Global hyper parameter\n",
    "    \n",
    "    def __init__(self,swarm_size=2,N= 2): \n",
    "        type(self).__counter += 1\n",
    "        self.swarm_size = swarm_size\n",
    "        self.N = N\n",
    "        self.swarm_ID = 'swarm_'+str(self.__counter)\n",
    "        self.swarm = []\n",
    "        \n",
    "    def __del__(self):\n",
    "        type(self).__counter -= 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def swarm_instances():\n",
    "        return PSO_NN_Swarm.__counter\n",
    "    \n",
    "    def populate_swarm(self):\n",
    "        \"\"\"Populate swarm with NN models.\"\"\"\n",
    "\n",
    "        for particle in range(self.swarm_size):\n",
    "            self.swarm.append(PSO_NN_Particle())\n",
    "        self.best_fitness = self.swarm[0].best_fitness  #Initialize with values of first particle\n",
    "        self.best_layers = self.swarm[0].layers\n",
    "        self.best_neurons = self.swarm[0].neurons\n",
    "        self.best_particle_ID = self.swarm[0].particle_ID\n",
    "        self.update_global_best()\n",
    "    \n",
    "    def show_swarm(self):\n",
    "        \"\"\"Show contents of swarm.\"\"\"\n",
    "        \n",
    "        print(\"Swarm ID:{}, Best fitness:{}, Best layers:{}, Best neurons:{}, Best particle:{}\"\n",
    "              .format(self.swarm_ID,self.best_fitness,self.best_layers,self.best_neurons,self.best_particle_ID))\n",
    "        for particle in self.swarm:\n",
    "            particle.show_particle()\n",
    "        \n",
    "    \n",
    "    def update_global_best(self):\n",
    "        \"\"\"Find particle with best fitness in swarm.\"\"\"\n",
    "        \n",
    "        for particle in self.swarm:\n",
    "            if particle.best_fitness < self.best_fitness:\n",
    "                self.best_fitness = particle.best_fitness\n",
    "                self.best_layers = particle.best_layers\n",
    "                self.best_neurons = particle.best_neurons\n",
    "                self.best_particle_ID = particle.particle_ID\n",
    "    \n",
    "    def velocity_change_global(self,particle):\n",
    "        \"\"\"Global component of particle velocity.\"\"\"\n",
    "        \n",
    "        particle.velocity_change_global_layers =  (self.best_layers - particle.layers)*self.c2*random.random()\n",
    "        particle.velocity_change_global_neurons = (self.best_neurons - particle.neurons)*self.c2*random.random()\n",
    "    \n",
    "   \n",
    "    def PSO_algorithm(self):\n",
    "        \"\"\"Apply PSO algorithm on swarm.\"\"\"\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            print(\"Iteration:{}\".format(i))\n",
    "            #self.update_global_best()\n",
    "            \n",
    "            for particle in self.swarm:\n",
    "                particle.velocity_change_inertial()\n",
    "                self.velocity_change_global(particle)\n",
    "                particle.update_particle_velocity()  \n",
    "                particle.update_particle()\n",
    "            self.update_global_best()\n",
    "            self.show_swarm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm1 = PSO_NN_Swarm(swarm_size=5,N=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a new NN model with ID:model_1 having 4 layers and 7 neurons per layer.\n",
      "Training a new NN model with ID:model_2 having 2 layers and 14 neurons per layer.\n",
      "Training a new NN model with ID:model_3 having 5 layers and 14 neurons per layer.\n",
      "Training a new NN model with ID:model_4 having 5 layers and 5 neurons per layer.\n",
      "Training a new NN model with ID:model_5 having 2 layers and 13 neurons per layer.\n"
     ]
    }
   ],
   "source": [
    "swarm1.populate_swarm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm1.swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_2, Fitness:1.587368, Layers:2, Neurons:14\n",
      "Particle ID:particle_3, Best fitness:1.130680, Best layers:5, Best neurons:14\n",
      "Model ID:model_3, Fitness:1.130680, Layers:5, Neurons:14\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_4, Fitness:2.204261, Layers:5, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_5, Fitness:1.433454, Layers:2, Neurons:13\n"
     ]
    }
   ],
   "source": [
    "swarm1.show_swarm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_6 having 2 layers and 13 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_7 having 4 layers and 13 neurons per layer.\n",
      "Updating model for particle particle_4.\n",
      "Training a new NN model with ID:model_8 having 4 layers and 5 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_9 having 2 layers and 12 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_6, Fitness:1.631794, Layers:2, Neurons:13\n",
      "Particle ID:particle_3, Best fitness:1.017958, Best layers:4, Best neurons:13\n",
      "Model ID:model_7, Fitness:1.017958, Layers:4, Neurons:13\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_9, Fitness:1.673476, Layers:2, Neurons:12\n",
      "Iteration:1\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_10 having 2 layers and 12 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_11 having 3 layers and 12 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_12 having 2 layers and 11 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_10, Fitness:7.188811, Layers:2, Neurons:12\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_11, Fitness:1.008346, Layers:3, Neurons:12\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_12, Fitness:2.107602, Layers:2, Neurons:11\n",
      "Iteration:2\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_13 having 2 layers and 11 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_14 having 3 layers and 11 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_15 having 2 layers and 10 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_13, Fitness:7.741020, Layers:2, Neurons:11\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_14, Fitness:1.649918, Layers:3, Neurons:11\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_15, Fitness:2.231092, Layers:2, Neurons:10\n",
      "Iteration:3\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_16 having 2 layers and 10 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_17 having 3 layers and 10 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_18 having 2 layers and 9 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_16, Fitness:4.122581, Layers:2, Neurons:10\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_17, Fitness:1.429024, Layers:3, Neurons:10\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_18, Fitness:5.665600, Layers:2, Neurons:9\n",
      "Iteration:4\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_19 having 2 layers and 9 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_20 having 3 layers and 9 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_21 having 2 layers and 8 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_19, Fitness:2.452514, Layers:2, Neurons:9\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_20, Fitness:1.401477, Layers:3, Neurons:9\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_21, Fitness:14.867811, Layers:2, Neurons:8\n",
      "Iteration:5\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_22 having 2 layers and 8 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_23 having 3 layers and 8 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_24 having 2 layers and 7 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_22, Fitness:9.890337, Layers:2, Neurons:8\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_23, Fitness:1.889697, Layers:3, Neurons:8\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_24, Fitness:19.077455, Layers:2, Neurons:7\n",
      "Iteration:6\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_25 having 2 layers and 7 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_26 having 3 layers and 7 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_25, Fitness:15.068350, Layers:2, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_26, Fitness:3.864323, Layers:3, Neurons:7\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_24, Fitness:19.077455, Layers:2, Neurons:7\n",
      "Iteration:7\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_27 having 3 layers and 7 neurons per layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_28 having 3 layers and 6 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.587368, Best layers:2, Best neurons:14\n",
      "Model ID:model_27, Fitness:2.128760, Layers:3, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_28, Fitness:5.998410, Layers:3, Neurons:6\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_8, Fitness:32.055486, Layers:4, Neurons:5\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_24, Fitness:19.077455, Layers:2, Neurons:7\n",
      "Iteration:8\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_29 having 4 layers and 7 neurons per layer.\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_30 having 3 layers and 5 neurons per layer.\n",
      "Updating model for particle particle_4.\n",
      "Training a new NN model with ID:model_31 having 4 layers and 6 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_32 having 2 layers and 8 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.991333931684494, Best layers:4, Best neurons:7, Best particle:particle_1\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:1.211031, Best layers:4, Best neurons:7\n",
      "Model ID:model_29, Fitness:1.211031, Layers:4, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_30, Fitness:4.174803, Layers:3, Neurons:5\n",
      "Particle ID:particle_4, Best fitness:2.204261, Best layers:5, Best neurons:5\n",
      "Model ID:model_31, Fitness:16.583488, Layers:4, Neurons:6\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_32, Fitness:4.023241, Layers:2, Neurons:8\n",
      "Iteration:9\n",
      "Updating model for particle particle_2.\n",
      "Training a new NN model with ID:model_33 having 5 layers and 7 neurons per layer.\n",
      "Updating model for particle particle_4.\n",
      "Training a new NN model with ID:model_34 having 4 layers and 7 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_35 having 2 layers and 9 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_30, Fitness:4.174803, Layers:3, Neurons:5\n",
      "Particle ID:particle_4, Best fitness:2.009461, Best layers:4, Best neurons:7\n",
      "Model ID:model_34, Fitness:2.009461, Layers:4, Neurons:7\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_35, Fitness:5.957836, Layers:2, Neurons:9\n",
      "Iteration:10\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_36 having 3 layers and 6 neurons per layer.\n",
      "Updating model for particle particle_4.\n",
      "Training a new NN model with ID:model_37 having 4 layers and 8 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_38 having 2 layers and 10 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_36, Fitness:10.295864, Layers:3, Neurons:6\n",
      "Particle ID:particle_4, Best fitness:1.041444, Best layers:4, Best neurons:8\n",
      "Model ID:model_37, Fitness:1.041444, Layers:4, Neurons:8\n",
      "Particle ID:particle_5, Best fitness:1.433454, Best layers:2, Best neurons:13\n",
      "Model ID:model_38, Fitness:2.263638, Layers:2, Neurons:10\n",
      "Iteration:11\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_39 having 3 layers and 7 neurons per layer.\n",
      "Updating model for particle particle_4.\n",
      "Training a new NN model with ID:model_40 having 4 layers and 9 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_41 having 3 layers and 11 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_39, Fitness:4.474642, Layers:3, Neurons:7\n",
      "Particle ID:particle_4, Best fitness:1.041444, Best layers:4, Best neurons:8\n",
      "Model ID:model_40, Fitness:1.657341, Layers:4, Neurons:9\n",
      "Particle ID:particle_5, Best fitness:1.303365, Best layers:3, Best neurons:11\n",
      "Model ID:model_41, Fitness:1.303365, Layers:3, Neurons:11\n",
      "Iteration:12\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_42 having 3 layers and 8 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_43 having 4 layers and 12 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_42, Fitness:1.844823, Layers:3, Neurons:8\n",
      "Particle ID:particle_4, Best fitness:1.041444, Best layers:4, Best neurons:8\n",
      "Model ID:model_40, Fitness:1.657341, Layers:4, Neurons:9\n",
      "Particle ID:particle_5, Best fitness:0.934813, Best layers:4, Best neurons:12\n",
      "Model ID:model_43, Fitness:0.934813, Layers:4, Neurons:12\n",
      "Iteration:13\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_44 having 3 layers and 9 neurons per layer.\n",
      "Updating model for particle particle_5.\n",
      "Training a new NN model with ID:model_45 having 5 layers and 12 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_44, Fitness:1.915049, Layers:3, Neurons:9\n",
      "Particle ID:particle_4, Best fitness:1.041444, Best layers:4, Best neurons:8\n",
      "Model ID:model_40, Fitness:1.657341, Layers:4, Neurons:9\n",
      "Particle ID:particle_5, Best fitness:0.891081, Best layers:5, Best neurons:12\n",
      "Model ID:model_45, Fitness:0.891081, Layers:5, Neurons:12\n",
      "Iteration:14\n",
      "Updating model for particle particle_3.\n",
      "Training a new NN model with ID:model_46 having 3 layers and 10 neurons per layer.\n",
      "Swarm ID:swarm_1, Best fitness:0.8050551068782806, Best layers:5, Best neurons:7, Best particle:particle_2\n",
      "Particle ID:particle_1, Best fitness:0.991334, Best layers:4, Best neurons:7\n",
      "Model ID:model_1, Fitness:0.991334, Layers:4, Neurons:7\n",
      "Particle ID:particle_2, Best fitness:0.805055, Best layers:5, Best neurons:7\n",
      "Model ID:model_33, Fitness:0.805055, Layers:5, Neurons:7\n",
      "Particle ID:particle_3, Best fitness:1.008346, Best layers:3, Best neurons:12\n",
      "Model ID:model_46, Fitness:1.246266, Layers:3, Neurons:10\n",
      "Particle ID:particle_4, Best fitness:1.041444, Best layers:4, Best neurons:8\n",
      "Model ID:model_40, Fitness:1.657341, Layers:4, Neurons:9\n",
      "Particle ID:particle_5, Best fitness:0.891081, Best layers:5, Best neurons:12\n",
      "Model ID:model_45, Fitness:0.891081, Layers:5, Neurons:12\n"
     ]
    }
   ],
   "source": [
    "swarm1.PSO_algorithm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
